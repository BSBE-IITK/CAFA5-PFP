{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom Bio import SeqIO\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import pad_sequences # padding sequences\nfrom keras.utils import to_categorical\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Embedding, Bidirectional, Dropout, Dense\nfrom tensorflow.compat.v1.keras.layers import CuDNNLSTM\nfrom tensorflow.keras.regularizers import l2,l1,l1_l2\nfrom keras.callbacks import EarlyStopping\nimport keras_tuner as kt\nfrom sklearn.metrics import accuracy_score\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-10T15:05:59.836246Z","iopub.execute_input":"2023-07-10T15:05:59.836622Z","iopub.status.idle":"2023-07-10T15:06:16.977676Z","shell.execute_reply.started":"2023-07-10T15:05:59.836592Z","shell.execute_reply":"2023-07-10T15:06:16.976570Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/cafa-5-protein-function-prediction/sample_submission.tsv\n/kaggle/input/cafa-5-protein-function-prediction/IA.txt\n/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\n/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset-taxon-list.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo\n/kaggle/input/train-targets-top500/train_targets_top500.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\ndef create_dict(codes):\n  char_dict = {}\n  for index, val in enumerate(codes):\n    char_dict[val] = index+1\n\n  return char_dict\n\nchar_dict = create_dict(codes)\n\nprint(char_dict)\nprint(\"Dict Length:\", len(char_dict))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:06:16.979745Z","iopub.execute_input":"2023-07-10T15:06:16.981318Z","iopub.status.idle":"2023-07-10T15:06:16.989564Z","shell.execute_reply.started":"2023-07-10T15:06:16.981280Z","shell.execute_reply":"2023-07-10T15:06:16.988553Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"{'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}\nDict Length: 20\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sequences = SeqIO.parse(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\", \"fasta\")","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:06:16.991113Z","iopub.execute_input":"2023-07-10T15:06:16.992091Z","iopub.status.idle":"2023-07-10T15:06:17.046138Z","shell.execute_reply.started":"2023-07-10T15:06:16.992016Z","shell.execute_reply":"2023-07-10T15:06:17.045027Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test_sequences = SeqIO.parse(\"/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\", \"fasta\")","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:06:17.049078Z","iopub.execute_input":"2023-07-10T15:06:17.049461Z","iopub.status.idle":"2023-07-10T15:06:17.061099Z","shell.execute_reply.started":"2023-07-10T15:06:17.049430Z","shell.execute_reply":"2023-07-10T15:06:17.059856Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_encode = []\nfor seq in train_sequences:\n    row_encode = []\n    for code in seq:\n        row_encode.append(char_dict.get(code, 0))\n    train_encode.append(np.array(row_encode))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:06:17.063550Z","iopub.execute_input":"2023-07-10T15:06:17.064617Z","iopub.status.idle":"2023-07-10T15:06:51.877425Z","shell.execute_reply.started":"2023-07-10T15:06:17.064575Z","shell.execute_reply":"2023-07-10T15:06:51.876396Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_encode = []\nfor seq in test_sequences:\n    row_encode = []\n    for code in seq:\n        row_encode.append(char_dict.get(code, 0))\n    test_encode.append(np.array(row_encode))","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:06:51.878862Z","iopub.execute_input":"2023-07-10T15:06:51.879425Z","iopub.status.idle":"2023-07-10T15:07:22.439252Z","shell.execute_reply.started":"2023-07-10T15:06:51.879389Z","shell.execute_reply":"2023-07-10T15:07:22.438254Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_encode[1]","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:22.440593Z","iopub.execute_input":"2023-07-10T15:07:22.441220Z","iopub.status.idle":"2023-07-10T15:07:22.457134Z","shell.execute_reply.started":"2023-07-10T15:07:22.441186Z","shell.execute_reply":"2023-07-10T15:07:22.456184Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([11,  3,  3, 15,  4,  3, 10, 18, 20, 14,  1,  9, 10,  1,  4, 14,  1,\n        4, 15, 20,  3,  4, 11, 18,  4, 16, 11,  9,  9, 18,  1,  6, 11,  3,\n       18,  4, 10, 17, 18,  4,  4, 15, 12, 10, 10, 16, 18,  1, 20,  9, 12,\n       18,  8,  6,  1, 15, 15,  1, 16, 19, 15,  8,  8, 16, 16,  8,  4, 14,\n        9,  4,  4, 12,  9,  6,  6,  4,  3,  9, 10,  9, 11,  8, 15,  4, 20,\n       15, 14, 11, 18,  4, 17,  4, 10,  9, 10,  8,  2,  2,  3,  8, 10,  3,\n       18, 10,  3,  9,  7, 10,  8, 13,  1,  1, 12, 17,  6,  4, 16,  9, 18,\n        5, 20, 20,  9, 11,  9,  6,  3, 20,  7, 15, 20, 10,  1,  4,  5,  1,\n       17,  6, 12,  3, 15,  9,  4,  1,  1,  4, 12, 16, 10, 18,  1, 20,  9,\n        1,  1, 16,  3,  8,  1, 11, 17,  4, 10, 13, 13, 17,  7, 13,  8, 15,\n       10,  6, 10,  1, 10, 12,  5, 16, 18,  5, 20, 20,  4,  8, 10, 12, 16,\n       13,  3, 15,  1,  2, 15, 10,  1,  9,  1,  1,  5,  3,  3,  1,  8,  1,\n        4, 10,  3, 17, 10, 16,  4,  4, 16, 20,  9,  3, 16, 17, 10,  8, 11,\n       14, 10, 10, 15,  3, 12, 10, 17, 10, 19, 17, 16,  3, 11, 14,  6,  3,\n        6,  4,  4, 14, 12,  9,  4,  1, 10, 14,  3, 18,  4,  3,  4, 12, 14])"},"metadata":{}}]},{"cell_type":"code","source":"train_data_size = int(len(train_encode)/2)\ntrain_data_size","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:22.458681Z","iopub.execute_input":"2023-07-10T15:07:22.459056Z","iopub.status.idle":"2023-07-10T15:07:22.469682Z","shell.execute_reply.started":"2023-07-10T15:07:22.459023Z","shell.execute_reply":"2023-07-10T15:07:22.468641Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"71123"},"metadata":{}}]},{"cell_type":"code","source":"train_encode = train_encode[:train_data_size]","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:22.472832Z","iopub.execute_input":"2023-07-10T15:07:22.473150Z","iopub.status.idle":"2023-07-10T15:07:22.504373Z","shell.execute_reply.started":"2023-07-10T15:07:22.473126Z","shell.execute_reply":"2023-07-10T15:07:22.503427Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Make length of all sequences equal 750 by padding smaller sequences and truncating larger ones","metadata":{}},{"cell_type":"code","source":"max_length = 750\ntrain_pad = pad_sequences(train_encode, maxlen=max_length, padding='post', truncating='post')\ntrain_pad.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:22.512468Z","iopub.execute_input":"2023-07-10T15:07:22.512851Z","iopub.status.idle":"2023-07-10T15:07:22.886535Z","shell.execute_reply.started":"2023-07-10T15:07:22.512827Z","shell.execute_reply":"2023-07-10T15:07:22.885504Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(71123, 750)"},"metadata":{}}]},{"cell_type":"code","source":"test_pad = pad_sequences(test_encode, maxlen=max_length, padding='post', truncating='post')\ntest_pad.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:22.888227Z","iopub.execute_input":"2023-07-10T15:07:22.888913Z","iopub.status.idle":"2023-07-10T15:07:23.606518Z","shell.execute_reply.started":"2023-07-10T15:07:22.888873Z","shell.execute_reply":"2023-07-10T15:07:23.605595Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(141865, 750)"},"metadata":{}}]},{"cell_type":"code","source":"Y = np.load('/kaggle/input/train-targets-top500/train_targets_top500.npy')","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:23.608072Z","iopub.execute_input":"2023-07-10T15:07:23.608505Z","iopub.status.idle":"2023-07-10T15:07:28.383684Z","shell.execute_reply.started":"2023-07-10T15:07:23.608471Z","shell.execute_reply":"2023-07-10T15:07:28.382710Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"Y = Y[:train_data_size,:]\nY.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:28.385332Z","iopub.execute_input":"2023-07-10T15:07:28.385747Z","iopub.status.idle":"2023-07-10T15:07:28.392214Z","shell.execute_reply.started":"2023-07-10T15:07:28.385712Z","shell.execute_reply":"2023-07-10T15:07:28.391365Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(71123, 500)"},"metadata":{}}]},{"cell_type":"code","source":"IX = np.arange(train_pad.shape[0])\nIX_train, IX_test, _,_ = train_test_split( IX, IX, train_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:28.393806Z","iopub.execute_input":"2023-07-10T15:07:28.394434Z","iopub.status.idle":"2023-07-10T15:07:28.407999Z","shell.execute_reply.started":"2023-07-10T15:07:28.394402Z","shell.execute_reply":"2023-07-10T15:07:28.406931Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"Y[IX_train,:].shape","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:28.409420Z","iopub.execute_input":"2023-07-10T15:07:28.409804Z","iopub.status.idle":"2023-07-10T15:07:28.464433Z","shell.execute_reply.started":"2023-07-10T15:07:28.409760Z","shell.execute_reply":"2023-07-10T15:07:28.463319Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(35561, 500)"},"metadata":{}}]},{"cell_type":"code","source":"x_input = Input(shape=(max_length,))\nemb = Embedding(800, 320, input_length=max_length)(x_input)\nbi_rnn = Bidirectional(CuDNNLSTM(64, kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.001)))(emb)\nx = Dropout(0.3)(bi_rnn)\nx = Dense(256,activation='relu')(x)\nx_output = Dense(500, activation='sigmoid')(x)\n\nmodel1 = Model(inputs=x_input, outputs=x_output)\nmodel1.compile(optimizer=keras.optimizers.Adam(0.0001), loss=tf.nn.sigmoid_cross_entropy_with_logits, metrics=['accuracy'])\n\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:28.466153Z","iopub.execute_input":"2023-07-10T15:07:28.466521Z","iopub.status.idle":"2023-07-10T15:07:34.337523Z","shell.execute_reply.started":"2023-07-10T15:07:28.466488Z","shell.execute_reply":"2023-07-10T15:07:34.336804Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 750)]             0         \n                                                                 \n embedding (Embedding)       (None, 750, 320)          256000    \n                                                                 \n bidirectional (Bidirectiona  (None, 128)              197632    \n l)                                                              \n                                                                 \n dropout (Dropout)           (None, 128)               0         \n                                                                 \n dense (Dense)               (None, 256)               33024     \n                                                                 \n dense_1 (Dense)             (None, 500)               128500    \n                                                                 \n=================================================================\nTotal params: 615,156\nTrainable params: 615,156\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 45\nbatch_size = 128","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:34.338521Z","iopub.execute_input":"2023-07-10T15:07:34.338863Z","iopub.status.idle":"2023-07-10T15:07:34.343570Z","shell.execute_reply.started":"2023-07-10T15:07:34.338830Z","shell.execute_reply":"2023-07-10T15:07:34.342603Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\nhistory1 = model1.fit(train_pad[IX_train,:], Y[IX_train,:], epochs=epochs, batch_size=batch_size,validation_split=0.1, callbacks=[es])","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:07:34.344893Z","iopub.execute_input":"2023-07-10T15:07:34.345257Z","iopub.status.idle":"2023-07-10T15:24:58.809660Z","shell.execute_reply.started":"2023-07-10T15:07:34.345223Z","shell.execute_reply":"2023-07-10T15:24:58.808549Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/45\n251/251 [==============================] - 34s 89ms/step - loss: 2.2892 - accuracy: 0.5565 - val_loss: 1.7804 - val_accuracy: 0.6860\nEpoch 2/45\n251/251 [==============================] - 22s 88ms/step - loss: 1.1608 - accuracy: 0.4850 - val_loss: 1.0483 - val_accuracy: 0.6860\nEpoch 4/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.9769 - accuracy: 0.5619 - val_loss: 0.9188 - val_accuracy: 0.6860\nEpoch 5/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.8817 - accuracy: 0.6115 - val_loss: 0.8515 - val_accuracy: 0.6860\nEpoch 6/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.8318 - accuracy: 0.6161 - val_loss: 0.8156 - val_accuracy: 0.6860\nEpoch 7/45\n251/251 [==============================] - 21s 85ms/step - loss: 0.8046 - accuracy: 0.6954 - val_loss: 0.7954 - val_accuracy: 0.6860\nEpoch 8/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7887 - accuracy: 0.6017 - val_loss: 0.7829 - val_accuracy: 0.6860\nEpoch 9/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7784 - accuracy: 0.7022 - val_loss: 0.7745 - val_accuracy: 0.6860\nEpoch 10/45\n251/251 [==============================] - 21s 85ms/step - loss: 0.7711 - accuracy: 0.6672 - val_loss: 0.7681 - val_accuracy: 0.6860\nEpoch 11/45\n251/251 [==============================] - 22s 86ms/step - loss: 0.7653 - accuracy: 0.5034 - val_loss: 0.7628 - val_accuracy: 0.6860\nEpoch 12/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7603 - accuracy: 0.3878 - val_loss: 0.7581 - val_accuracy: 0.6860\nEpoch 13/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7559 - accuracy: 0.4424 - val_loss: 0.7538 - val_accuracy: 0.6860\nEpoch 14/45\n251/251 [==============================] - 22s 89ms/step - loss: 0.7517 - accuracy: 0.6736 - val_loss: 0.7498 - val_accuracy: 0.6860\nEpoch 15/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7478 - accuracy: 0.4912 - val_loss: 0.7460 - val_accuracy: 0.6860\nEpoch 16/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7441 - accuracy: 0.7126 - val_loss: 0.7424 - val_accuracy: 0.6860\nEpoch 17/45\n251/251 [==============================] - 21s 85ms/step - loss: 0.7405 - accuracy: 0.7125 - val_loss: 0.7389 - val_accuracy: 0.6860\nEpoch 18/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7371 - accuracy: 0.6445 - val_loss: 0.7356 - val_accuracy: 0.6860\nEpoch 19/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7339 - accuracy: 0.7111 - val_loss: 0.7324 - val_accuracy: 0.6860\nEpoch 20/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7308 - accuracy: 0.6869 - val_loss: 0.7293 - val_accuracy: 0.6860\nEpoch 21/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7278 - accuracy: 0.7084 - val_loss: 0.7264 - val_accuracy: 0.6860\nEpoch 22/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7250 - accuracy: 0.7126 - val_loss: 0.7237 - val_accuracy: 0.6860\nEpoch 23/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7223 - accuracy: 0.7126 - val_loss: 0.7210 - val_accuracy: 0.6860\nEpoch 24/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7197 - accuracy: 0.6954 - val_loss: 0.7186 - val_accuracy: 0.6860\nEpoch 25/45\n251/251 [==============================] - 22s 86ms/step - loss: 0.7173 - accuracy: 0.7069 - val_loss: 0.7162 - val_accuracy: 0.6860\nEpoch 26/45\n251/251 [==============================] - 21s 86ms/step - loss: 0.7150 - accuracy: 0.7126 - val_loss: 0.7140 - val_accuracy: 0.6860\nEpoch 27/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7128 - accuracy: 0.7126 - val_loss: 0.7119 - val_accuracy: 0.6860\nEpoch 28/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7108 - accuracy: 0.7118 - val_loss: 0.7099 - val_accuracy: 0.6860\nEpoch 29/45\n251/251 [==============================] - 22s 86ms/step - loss: 0.7089 - accuracy: 0.4568 - val_loss: 0.7081 - val_accuracy: 0.6860\nEpoch 30/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7071 - accuracy: 0.6961 - val_loss: 0.7063 - val_accuracy: 0.6860\nEpoch 31/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7054 - accuracy: 0.3822 - val_loss: 0.7047 - val_accuracy: 0.6860\nEpoch 32/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7039 - accuracy: 0.7126 - val_loss: 0.7032 - val_accuracy: 0.6860\nEpoch 33/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.7025 - accuracy: 0.7126 - val_loss: 0.7019 - val_accuracy: 0.6860\nEpoch 34/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.7011 - accuracy: 0.7126 - val_loss: 0.7006 - val_accuracy: 0.6860\nEpoch 35/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.6999 - accuracy: 0.7126 - val_loss: 0.6995 - val_accuracy: 0.6860\nEpoch 36/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.6989 - accuracy: 0.5244 - val_loss: 0.6984 - val_accuracy: 0.6860\nEpoch 37/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.6979 - accuracy: 0.7126 - val_loss: 0.6975 - val_accuracy: 0.6860\nEpoch 38/45\n251/251 [==============================] - 22s 86ms/step - loss: 0.6970 - accuracy: 0.7126 - val_loss: 0.6967 - val_accuracy: 0.6860\nEpoch 39/45\n251/251 [==============================] - 21s 85ms/step - loss: 0.6962 - accuracy: 0.7126 - val_loss: 0.6959 - val_accuracy: 0.6860\nEpoch 40/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.6955 - accuracy: 0.5950 - val_loss: 0.6953 - val_accuracy: 0.6860\nEpoch 41/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.6949 - accuracy: 0.7126 - val_loss: 0.6947 - val_accuracy: 0.6860\nEpoch 42/45\n251/251 [==============================] - 22s 87ms/step - loss: 0.6944 - accuracy: 0.7126 - val_loss: 0.6943 - val_accuracy: 0.6860\nEpoch 43/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.6939 - accuracy: 0.4678 - val_loss: 0.6939 - val_accuracy: 0.6860\nEpoch 44/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.6936 - accuracy: 0.7126 - val_loss: 0.6935 - val_accuracy: 0.6860\nEpoch 45/45\n251/251 [==============================] - 22s 88ms/step - loss: 0.6933 - accuracy: 0.5321 - val_loss: 0.6933 - val_accuracy: 0.6860\n","output_type":"stream"}]},{"cell_type":"code","source":"Y_pred = model1.predict(train_pad[IX_test,:])","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:26:00.518200Z","iopub.execute_input":"2023-07-10T15:26:00.518550Z","iopub.status.idle":"2023-07-10T15:26:41.652827Z","shell.execute_reply.started":"2023-07-10T15:26:00.518520Z","shell.execute_reply":"2023-07-10T15:26:41.651717Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"1112/1112 [==============================] - 25s 23ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def normalize_vector(vector):\n    min_val = np.min(vector)\n    max_val = np.max(vector)\n    normalized_vector = (vector - min_val) / (max_val - min_val)\n    return normalized_vector","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:26:44.284369Z","iopub.execute_input":"2023-07-10T15:26:44.284754Z","iopub.status.idle":"2023-07-10T15:26:44.289874Z","shell.execute_reply.started":"2023-07-10T15:26:44.284723Z","shell.execute_reply":"2023-07-10T15:26:44.288945Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def F1_score(y_pred,y_target):\n    y_pred = normalize_vector(y_pred)\n    threshold = 0.5\n    val_preds = np.where(y_pred> threshold, 1, 0)\n    val_labels = y_target\n    tp = np.sum((val_preds == 1) & (val_labels == 1))\n    fp = np.sum((val_preds == 1) & (val_labels == 0))\n    fn = np.sum((val_preds == 0) & (val_labels == 1))\n    if tp+fp == 0:\n        return 0\n    precision = tp / (tp + fp)\n    if tp+fn == 0:\n        return 0\n    recall = tp / (tp + fn)\n    if (precision + recall) == 0:\n        return 0\n    f1_score = 2 * (precision * recall) / (precision + recall)\n\n    return f1_score","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:26:45.751618Z","iopub.execute_input":"2023-07-10T15:26:45.752357Z","iopub.status.idle":"2023-07-10T15:26:45.761855Z","shell.execute_reply.started":"2023-07-10T15:26:45.752316Z","shell.execute_reply":"2023-07-10T15:26:45.760975Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"normalize_vector(Y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:26:50.023130Z","iopub.execute_input":"2023-07-10T15:26:50.023872Z","iopub.status.idle":"2023-07-10T15:26:50.071223Z","shell.execute_reply.started":"2023-07-10T15:26:50.023837Z","shell.execute_reply":"2023-07-10T15:26:50.070108Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([[9.7858191e-01, 9.7032171e-01, 9.1440189e-01, ..., 4.4406365e-06,\n        5.0281469e-06, 4.2971601e-06],\n       [9.7293562e-01, 9.6484977e-01, 9.0791476e-01, ..., 6.6716680e-06,\n        7.4714676e-06, 6.4657365e-06],\n       [9.7245139e-01, 9.6434128e-01, 9.0733850e-01, ..., 6.8708609e-06,\n        7.6891793e-06, 6.6626158e-06],\n       ...,\n       [9.7746247e-01, 9.6917224e-01, 9.1306496e-01, ..., 4.8082625e-06,\n        5.4303682e-06, 4.6585851e-06],\n       [9.7361863e-01, 9.6553642e-01, 9.0871054e-01, ..., 6.3838306e-06,\n        7.1572958e-06, 6.1841183e-06],\n       [9.7888684e-01, 9.7063464e-01, 9.1476738e-01, ..., 4.3434738e-06,\n        4.9218170e-06, 4.2017195e-06]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"F1_score(Y_pred,Y[IX_test,:])","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:26:58.011438Z","iopub.execute_input":"2023-07-10T15:26:58.011840Z","iopub.status.idle":"2023-07-10T15:26:58.289088Z","shell.execute_reply.started":"2023-07-10T15:26:58.011807Z","shell.execute_reply":"2023-07-10T15:26:58.287818Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.1653069267012722"},"metadata":{}}]},{"cell_type":"code","source":"predictions = model1.predict(test_pad)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:29:17.816878Z","iopub.execute_input":"2023-07-10T15:29:17.817243Z","iopub.status.idle":"2023-07-10T15:31:02.277686Z","shell.execute_reply.started":"2023-07-10T15:29:17.817213Z","shell.execute_reply":"2023-07-10T15:31:02.276512Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"4434/4434 [==============================] - 101s 23ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:31:14.283481Z","iopub.execute_input":"2023-07-10T15:31:14.283893Z","iopub.status.idle":"2023-07-10T15:31:14.290179Z","shell.execute_reply.started":"2023-07-10T15:31:14.283861Z","shell.execute_reply":"2023-07-10T15:31:14.289189Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(141865, 500)"},"metadata":{}}]},{"cell_type":"code","source":"np.save(\"pred.npy\", predictions)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T15:32:14.135969Z","iopub.execute_input":"2023-07-10T15:32:14.136702Z","iopub.status.idle":"2023-07-10T15:32:14.347310Z","shell.execute_reply.started":"2023-07-10T15:32:14.136644Z","shell.execute_reply":"2023-07-10T15:32:14.346218Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Manual HyperParameter Tuning","metadata":{}},{"cell_type":"code","source":"num_epochs = 10\nbatch_sz = 256\n\nparam_grid = {\n    'lstm_units': [256,512],\n    'dropout_rate': [0.05,0.001],\n#     'kernel_regularizer': [None, l1(0.01), l2(0.01), l1_l2(l1=0.01, l2=0.01)],\n#     'recurrent_regularizer': [None, l1(0.01), l2(0.01), l1_l2(l1=0.01, l2=0.01)],\n#     'bias_regularizer': [None, l1(0.01), l2(0.01), l1_l2(l1=0.01, l2=0.01)]\n}\n\n# Generate all combinations of hyperparameters\nhyperparams = np.array(np.meshgrid(*param_grid.values())).T.reshape(-1, len(param_grid))\n\nbest_accuracy = 0\nbest_hyperparams = None\n\nfor params in hyperparams:\n    lstm_units, dropout_rate,kernel_regularizer,recurrent_regularizer,bias_regularizer = params\n\n    x_input = Input(shape=(max_length,))\n    emb = Embedding(21, 128, input_length=max_length)(x_input)\n    bi_rnn = Bidirectional(CuDNNLSTM(int(lstm_units), kernel_regularizer=kernel_regularizer,\n                                     recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer))(emb)\n    x = Dropout(dropout_rate)(bi_rnn)\n    x_output = Dense(500, activation='softmax')(x)\n    model = Model(inputs=x_input, outputs=x_output)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the model\n    print(f\"\\n #### current model : {params} ### \")\n    model.fit(train_pad[IX_train,:], Y[IX_train,:], epochs=num_epochs, batch_size=batch_sz,validation_split=0.1, callbacks=[es])\n\n    # Evaluate on validation set\n    val_predictions = model.predict(train_pad[IX_test,:])\n    val_accuracy = accuracy_score(np.argmax(Y[IX_test,:], axis=1), np.argmax(val_predictions, axis=1))\n    f1_score = F1_score(normalize_vector(val_predictions),Y[IX_test,:])\n    # Check if current hyperparameters are the best so far\n    print(f\"model-{params}-val acc = {val_accuracy}\")\n    print(f\"model-{params}-f1 score = {f1_score}\")\n    if val_accuracy > best_accuracy:\n        best_accuracy = val_accuracy\n        best_hyperparams = params\n\n# Print the best hyperparameters and accuracy\nprint(\"Best Hyperparameters:\", best_hyperparams)\nprint(\"Best Accuracy:\", best_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Keras Tuner for hyperparam tuning","metadata":{}},{"cell_type":"code","source":"def model_builder(hp):\n    x_input = Input(shape=(max_length,))\n    hp_emb_input_units = hp.Int('input_dim', min_value=100, max_value=1000, step=100)\n    hp_emb_output_units = hp.Int('output_dim', min_value=64, max_value=512, step=64)\n    emb = Embedding(hp_emb_input_units, hp_emb_output_units, input_length=max_length)(x_input)\n    hp_lstm_units = hp.Int('units', min_value=64, max_value=512, step=64)\n    hp_kernel_reg = hp.Choice('kernel_regularizer', values=[1e-2,1e-3,1e-4])\n    hp_recurrent_reg = hp.Choice('recurrent_regularizer', values=[1e-2,1e-3,1e-4])\n    hp_bias_reg = hp.Choice('bias_regularizer', values=[1e-2,1e-3,1e-4])\n    bi_rnn = Bidirectional(CuDNNLSTM(hp_lstm_units, kernel_regularizer=l2(hp_kernel_reg), recurrent_regularizer=l2(hp_recurrent_reg), bias_regularizer=l2(hp_bias_reg)))(emb)\n    x = Dropout(0.1)(bi_rnn)\n    hp_dense_units = hp.Int('units', min_value=64, max_value=512, step=64)\n    x = Dense(512,activation='relu')(x)\n\n    # softmax classifier\n    x_output = Dense(500, activation='sigmoid')(x)\n\n    model = Model(inputs=x_input, outputs=x_output)\n\n  # Tune the learning rate for the optimizer\n  # Choose an optimal value from 0.01, 0.001, or 0.0001\n    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4, 1e-5, 1e-6])\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n#     model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n#                 loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n#                 metrics=['accuracy'])\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner = kt.Hyperband(model_builder,\n                     objective='val_accuracy',\n                     max_epochs=30,\n                     factor=3,\n                     directory='lstm',\n                     project_name='kt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_early = EarlyStopping(monitor='val_loss', patience=5, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search(train_pad[IX_train,:], Y[IX_train,:], epochs=30, batch_size=128,validation_split=0.1,verbose=1, callbacks=[stop_early])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best Hyperparameters:\")\nfor param, value in best_hps.values.items():\n    print(f\"{param}: {value}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tuner.hypermodel.build(best_hps)\nhistory = model.fit(train_pad[IX_test,:], Y[IX_test,:], epochs=50, validation_split=0.1, callbacks = [stop_early])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Plot training and validation accuracy\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(train_pad[IX_test,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"F1_score(normalize_vector(y_pred),Y[IX_test,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_test = model.predict(test_pad)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(\"bilstm-full-v2.npy\",Y_pred_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LSTM v1 =>   \n    Best Hyperparameters:  \n    units: 147  \n    kernel_regularizer: 0.01  \n    recurrent_regularizer: 0.01  \n    bias_regularizer: 0.01  \n    learning_rate: 1e-05  \n    tuner/epochs: 2  \n    tuner/initial_epoch: 0  \n    tuner/bracket: 2  \n    tuner/round: 0  \n      \nF-max = 0.16\n\nLSTM v2 =>  \n    Best Hyperparameters:  \n    input_dim: 210  \n    output_dim: 128  \n    units: 256  \n    kernel_regularizer: 0.01  \n    recurrent_regularizer: 0.001  \n    bias_regularizer: 0.001  \n    learning_rate: 1e-05  \n    tuner/epochs: 2  \n    tuner/initial_epoch: 0  \n    tuner/bracket: 2  \n    tuner/round: 0  \n  \nF-max = 0.16","metadata":{}}]}